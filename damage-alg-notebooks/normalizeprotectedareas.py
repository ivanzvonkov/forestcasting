# -*- coding: utf-8 -*-
"""NormalizeProtectedAreas.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sAfnUu5qFUpjHi0Z9znseXlmZ4jFEdCU
"""

from osgeo import ogr
from google.colab import files, drive
import pandas as pd
import numpy as np
import os

drive.mount('/content/gdrive')
root_path = '/content/gdrive/My Drive/Capstone Public Folder/Data/'

def gatherDataset(province):
  pa = pd.read_csv(root_path + f'{province} Location/{province}_protected_areas_grid.csv.gz', compression = "gzip")
  eco = pd.read_csv(root_path + f'{province} Location/{province}_data_with_eco.csv.gz', compression = "gzip")
  eco = eco[["KEY", 'ECOZONE', 'ECOREGION', 'ECODISTRICT']]

  df = pd.merge(pa, eco, how = 'left', left_on = "KEY", right_on = "KEY")
  return df

AL_PA = gatherDataset("AL")
QB_PA = gatherDataset("QB")
BC_PA = gatherDataset("BC")
ON_PA = gatherDataset("ON")
SK_PA = gatherDataset("SK")
MB_PA = gatherDataset("MB")

data_sets = [AL_PA,QB_PA, BC_PA, ON_PA, SK_PA, MB_PA]

PA_df = pd.concat(data_sets)
PA_df

"""Normalize Over All Area"""

def normalization(count, min, max):
  norm = (count - min) / (max - min)
  return norm

min_count = PA_df["PA_COUNT"].min()
max_count= PA_df["PA_COUNT"].max()


PA_df["NORM"] = np.vectorize(normalization)(PA_df["PA_COUNT"], min_count, max_count)
PA_df["log"] = np.log(PA_df["PA_COUNT"] + 1)
PA_df["LOG_NORM"] = np.vectorize(normalization)(PA_df["log"], PA_df["log"].min(),  PA_df["log"].max())

PA_df["PA_COUNT"].hist()

PA_df['LOG_NORM'].hist()

root_path = '/content/gdrive/My Drive/Capstone Public Folder/Notebooks-DamageAlg/ProtectedAreas/'
PA_df[["KEY", "PA_COUNT", "LOG_NORM"]].to_csv(root_path + 'normalized_PA_log.csv.gz', compression = "gzip", index = False)
PA_df[["KEY", "PA_COUNT", "NORM"]].to_csv(root_path + 'normalized_PA.csv.gz', compression = "gzip", index = False)