# -*- coding: utf-8 -*-
"""2d-grid_to_fire_point_mapping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/173q_9PGVCPPwX3oFmyYTwQcBuMsr6XOC
"""

import pandas as pd
import numpy as np
import sys
from google.colab import files, drive

# Mount Google Drive
drive.mount('/content/gdrive')
province = "BC"  
root_path = '/content/gdrive/My Drive/Capstone Public Folder/Data/'
province_path = root_path + province + ' Location/'
colab_path = root_path + 'Colab Data/'
yearLimit = 1983 #inclusive filter - All data needed for calculating stats

def roundToDecimal(number, toDecimal):
    rounded = round(number*toDecimal)/toDecimal
    return(rounded)

def createLocationKey(lat, lng):
    lowerLat = roundToDecimal(lat, 5)
    lowerLong = roundToDecimal(lng, 5)

    key = str(lowerLat) + "|" + str(lowerLong)
    return(key)

def createLocationYearKey(locationKey, year):
    return locationKey + "|" + str(year)

def makeNumDoubleDigit(num):
    if num < 10:
        num = "0" + str(num)

    return str(num)

def createStartDate(year, month, day):
    year = makeNumDoubleDigit(year)
    month = makeNumDoubleDigit(month)
    day = makeNumDoubleDigit(day)

    return year + "-" + month + "-" + day

fire_point_df = pd.read_csv(colab_path + "CAN_fire_point_data.csv.gz", compression = "gzip")
fire_point_df = fire_point_df[["SRC_AGENCY", "FIRE_ID", "LATITUDE", "LONGITUDE", "YEAR", "MONTH", "DAY", "OUT_DATE", "SIZE_HA", "ECODISTRIC", "ECOREGION", "ECOZONE"]]

#create start date field
fire_point_df["START_DATE"] = np.vectorize(createStartDate)(fire_point_df["YEAR"], fire_point_df["MONTH"], fire_point_df["DAY"])

#filter on province
filterValue = province
if province == "AL":
  filterValue = "AB" #this firepoint data has alberta as AB not AL so we have to convert for the filter
elif province == "QB":
  filterValue = "QC"

fire_point_df = fire_point_df[fire_point_df["SRC_AGENCY"].eq(filterValue)]

#filter on start date
fire_point_df = fire_point_df[fire_point_df["YEAR"] >= yearLimit]

# create locationKey and locationYearKey
fire_point_df['locationKey'] = np.vectorize(createLocationKey)(fire_point_df['LATITUDE'], fire_point_df['LONGITUDE'])
fire_point_df['locationYearKey'] = np.vectorize(createLocationYearKey)(fire_point_df['locationKey'], fire_point_df['YEAR'])

# Drop unneeded fields 
fire_point_df = fire_point_df[["locationKey", "locationYearKey", "YEAR", "MONTH", "FIRE_ID", "LATITUDE", "LONGITUDE","START_DATE", "OUT_DATE", "SIZE_HA", "ECODISTRIC", "ECOREGION", "ECOZONE"]]

print(fire_point_df.head())

print(f'Length before: {len(fire_point_df)}')
print(f'Length after: {len(fire_point_df.drop_duplicates())}')
fire_point_df = fire_point_df.drop_duplicates()

# Write Out CSV
fire_point_df.to_csv(province_path + province + "_fire_location_grid.csv.gz", compression = 'gzip', index = False)