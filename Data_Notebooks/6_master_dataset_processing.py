# -*- coding: utf-8 -*-
"""6-master_dataset_processing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fPkOKqBWn4ow70ifixRjPOyCorKH0D4o

# Master Dataset Processing
**Input: {province}_dataset.csv.gz**
*   Full dataset of features for given province

**Output: {province}_processed_sample_dataset.csv.gz**

*   Split 40/60 fire/no fire
*   Null and NaN values filled
*   Create new features to better represent data
*   Create bins for continous values
"""

# Set province 
province = 'AL'
root_path = '/content/gdrive/My Drive/Capstone Public Folder/Data/'

# Commented out IPython magic to ensure Python compatibility.
# Imports
import pandas as pd
import numpy as np
import io
from google.colab import files, drive
import zipfile
import gzip
import shutil
from math import isnan, nan, exp
import datetime

# visualization
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

# Mount Google Drive
drive.mount('/content/gdrive')

# Master Dataset Path
master_path = root_path + f'Colab Data/{province}_dataset.csv.gz'
master_df = pd.read_csv(master_path, compression='gzip')

master_df.head()

# Which features contain null or NaN values
null_columns=master_df.columns[master_df.isnull().any()]
master_df[null_columns].isnull().sum()

master_df.drop(['LOCATION_KEY', 'HEAT_DEG_DAYS', 'COOL_DEG_DAYS'], axis=1, inplace=True)

# Make 40 fire / 60 no fire split
fire_df = master_df[master_df['FIRE'] == 1]
no_fire_df = master_df[master_df['FIRE'] == 0]
fire_amount = len(fire_df)
no_fire_amount = len(no_fire_df)
desired_no_fire_amount = fire_amount*(0.6/0.4)
desired_no_fire_fraction = desired_no_fire_amount / no_fire_amount
no_fire_sample_df = no_fire_df.sample(frac=desired_no_fire_fraction)
sample_df = pd.concat([fire_df, no_fire_sample_df], axis=0)
sample_df.describe()

"""### Describing Features
* **Max/Mean/Min Temp**: Continous numerical
* **Total Rain/Total Precipitation/Total Snow/Snow on Grnd**: Continous numerical
* **Dir of Max Gust**: Continous numerical
* **Speed of Max Gust**: Combination of data types
* **Fire**: Categorical nominal
"""

# Which features contain null or NaN values
null_columns=sample_df.columns[sample_df.isnull().any()]
sample_df[null_columns].isnull().sum()

"""### Part 1: How to fill in null values?
* **Max/Mean/Min Temp**: If some value is available use it, else compare days before and after and use average between two
* **Total Rain/Total Precipitation/Total Snow/Snow on Grnd**: Put 0 for all NaN values
* **Dir of Max Gust**: If speed is 0 this is also 0 else random
* **Speed of Max Gust**: If NaN make it 0, if some value with '<' remove the '<'
"""

# Fill NaN with 0 where applicable
cols = ['TOTAL_RAIN', 
        'TOTAL_PRECIP', 
        'TOTAL_SNOW',
        'SNOW_ON_GRND',
        'SPD_OF_MAX_GUST',
        'TOTAL_SIZE_HA_OLD',
        'AVERAGE_SIZE_HA_OLD',
        'TOTAL_DURATION_OLD',
        'AVERAGE_DURATION_OLD'
      ]

sample_df[cols] = sample_df[cols].fillna(value = 0);

# calculate averages
keys = ['MEAN_TEMP', 'MIN_TEMP', 'MAX_TEMP', 'TEMP_12_4', 'DEW_POINT_TEMP_12_4', 'REL_HUM_12_4']
averages = {}
for key in keys:
  averages[key] = master_df[key].mean()

def fill_temp(row):
  
  # Get key
  location_date_key = row['LOCATION_DATE_KEY'].split('|')
  location = '|'.join(location_date_key[:2])
  row_date = location_date_key[2]

  date_time_obj = datetime.datetime.strptime(row_date, '%Y-%m-%d')
  date_before = (date_time_obj - datetime.timedelta(days=1)).date()
  date_after = (date_time_obj + datetime.timedelta(days=1)).date()

  location_date_key_before = location + '|' + str(date_before)
  location_date_key_after = location + '|' + str(date_after)

  row_before = master_df[master_df['LOCATION_DATE_KEY'] == location_date_key_before]
  row_after = master_df[master_df['LOCATION_DATE_KEY'] == location_date_key_after]
  
  no_nan_values = True
  all_nan_values = True
  all_nan_values_filled = True

  for key in keys: 
    if no_nan_values and isnan(row[key]):
      no_nan_values = False
    
    if all_nan_values and not isnan(row[key]):
      all_nan_values = False

    if len(row_before) == 1:
      yesterday_val = row_before.iloc[0][key]
    else:
      yesterday_val = nan 

    if len(row_after) == 1:
      tomorrow_val = row_after.iloc[0][key]
    else:
      tomorrow_val = nan

    if not isnan(yesterday_val) and not isnan(tomorrow_val):
      row[key] = (yesterday_val + tomorrow_val)/2
    elif all_nan_values_filled:
      all_nan_values_filled = False

  if no_nan_values or all_nan_values_filled:
    return row 

  # Try to use other values in row to fill info 
  # If temperatures are not all nan, derive other temperatures from available value
  if isnan(row['MEAN_TEMP']):
    if not isnan(row['MAX_TEMP']) and not isnan(row['MIN_TEMP']):
      row['MEAN_TEMP'] = (row['MAX_TEMP'] + row['MIN_TEMP'])/2
    elif not isnan(row['MIN_TEMP']):
      row['MEAN_TEMP'] = row['MIN_TEMP'] + 5
    elif not isnan(row['MAX_TEMP']):
      row['MEAN_TEMP'] = row['MAX_TEMP'] - 5
    else:
      row['MEAN_TEMP'] = averages['MEAN_TEMP']
  
  if isnan(row['MIN_TEMP']):
    if not isnan(row['MEAN_TEMP']):
      row['MIN_TEMP'] = row['MEAN_TEMP'] - 5
    elif not isnan(row['MAX_TEMP']):
      row['MIN_TEMP'] = row['MAX_TEMP'] - 10
    else:
      row['MIN_TEMP'] = averages['MIN_TEMP']

  if isnan(row['MAX_TEMP']):
    if not isnan(row['MEAN_TEMP']):
      row['MAX_TEMP'] = row['MEAN_TEMP'] + 5
    elif not isnan(row['MIN_TEMP']):
      row['MAX_TEMP'] = row['MIN_TEMP'] + 10
    else:
      row['MAX_TEMP'] = averages['MAX_TEMP']

  if isnan(row['TEMP_12_4']):
    row['TEMP_12_4'] = row['MAX_TEMP']

  if isnan(row['DEW_POINT_TEMP_12_4']):
    row['DEW_POINT_TEMP_12_4'] = averages['DEW_POINT_TEMP_12_4']

  if isnan(row['REL_HUM_12_4']):  
    row['REL_HUM_12_4'] = averages['REL_HUM_12_4']

  return row

sample_df = sample_df.apply(lambda row: fill_temp(row), axis=1)

# Fix wind values 
def fix_wind(row):
  try:
   row['SPD_OF_MAX_GUST'] = int(row['SPD_OF_MAX_GUST'])
  except:
    row['SPD_OF_MAX_GUST'] = int(row['SPD_OF_MAX_GUST'][1:])
  return row
  
sample_df = sample_df.apply(lambda row: fix_wind(row), axis=1)

# Sub in -1 for max gust if empty
sample_df['DIR_OF_MAX_GUST'] = sample_df['DIR_OF_MAX_GUST'].fillna(value = -1);

# Verify null values 
null_columns=sample_df.columns[sample_df.isnull().any()]
sample_df[null_columns].isnull().sum()

# Empty series means no nan values

"""### Part 2: Assumptions
* **Max/Mean/Min Temp/Temp 12-4**: Higher temperature correlates with higher chance of fire.

* **Total Rain/Total Precipitation/Total Snow/Snow on Grnd**: Must all be zero for fire to be possibe

* **Dir of Max Gust**: Direction most likely has no impact
* **Speed of Max Gust**: Higher wind correlates with fire occurance

* **Dew point temp 12-4**: Higher dew point temperature correlates with hotter weather and higher fire occurence

* **Relative humidity 12-4**: Higher relative humidity correlates higher change of fire

### Part 3: Correlations and Conclusions
"""

# Correlations between temperatures and label
g = sns.FacetGrid(sample_df, col='FIRE')
g.map(plt.hist, 'MEAN_TEMP', bins=10)

g = sns.FacetGrid(sample_df, col='FIRE')
g.map(plt.hist, 'MAX_TEMP', bins=10)

g = sns.FacetGrid(sample_df, col='FIRE')
g.map(plt.hist, 'MIN_TEMP', bins=10)

g = sns.FacetGrid(sample_df, col='FIRE')
g.map(plt.hist, 'TEMP_12_4', bins=10)

"""### 3a: Conclusions from above
Confirms assumption of higher temperature resulting in higher fire chance. Will keep all temperaure values as Min, Mean, and Max have different distributions.
"""

# Correlations between precipation and label
g = sns.FacetGrid(sample_df, col='FIRE')
g.map(plt.hist, 'TOTAL_RAIN')

# Precipitation is more general
g = sns.FacetGrid(sample_df, col='FIRE')
g.map(plt.hist, 'TOTAL_PRECIP')

"""### 3b: Conclusions from above
1. Fires can still occur when rain is present.
2. lot's of precipitation (ie over 20 mm) looks results in no fires. Will need to ensure bins of precipitation account for this.
"""

g = sns.FacetGrid(sample_df, col='FIRE')
g.map(plt.hist, 'TOTAL_SNOW')

g = sns.FacetGrid(sample_df, col='FIRE')
g.map(plt.hist, 'SNOW_ON_GRND')

"""### 3c: Conclusions from above
Fires only occur when snow on ground and total snow is 0. Can create feature IS_SNOW_ON_GRND and IS_SNOW_FALLING
"""

g = sns.FacetGrid(sample_df, col='FIRE')
g.map(plt.hist, 'SPD_OF_MAX_GUST')

g = sns.FacetGrid(sample_df, col='FIRE')
g.map(plt.hist, 'DIR_OF_MAX_GUST')

"""### 3d: Conclusion from above
The big gap between 5-30 with wind speed is due to all values such as '<30' were converted to simply '30'.
Overall direction of gust does not seem to impact the fire occurrence. Speed of max gust also shows a similar distribution with or without fire meaning no correlation.
"""

g = sns.FacetGrid(sample_df, col='FIRE')
g.map(plt.hist, 'DEW_POINT_TEMP_12_4')

g = sns.FacetGrid(sample_df, col='FIRE')
g.map(plt.hist, 'REL_HUM_12_4')

"""### 3e: Conclusions from above
Dew point temp must be above 0 for fire to happen. 

No strong correlation between relative humidity. Absolute humidity should be calculated for more a useful feature.
"""

g = sns.FacetGrid(sample_df, col='FIRE')
g.map(plt.hist, 'TOTAL_SIZE_HA_OLD')

g = sns.FacetGrid(sample_df, col='FIRE')
g.map(plt.hist, 'AVERAGE_SIZE_HA_OLD')

g = sns.FacetGrid(sample_df, col='FIRE')
g.map(plt.hist, 'TOTAL_DURATION_OLD')

g = sns.FacetGrid(sample_df, col='FIRE')
g.map(plt.hist, 'AVERAGE_DURATION_OLD')

"""### 3f: Conclusions from above
Only TOTAL_DURATION_OLD has some correlation with the occurence of fires.

## Part 4: Creating new features

### 4a: Snow features
Based on conclusions will create feature IS_SNOW_ON_GROUND , IS_SNOW_FALLING
"""

# Fill empty dates 
def create_snow_features(row):
  row['IS_SNOW_ON_GROUND'] = row['SNOW_ON_GRND'] > 0
  row['IS_SNOW_FALLING'] = row['TOTAL_SNOW'] > 0
  return row
  
sample_df = sample_df.apply(lambda row: create_snow_features(row), axis=1)

"""### 4b Humidity features
Create absolute humidity feature

Based on: https://carnotcycle.wordpress.com/2012/08/04/how-to-convert-relative-humidity-to-absolute-humidity/
"""

def create_abs_humidity(row):
  t = row['TEMP_12_4']
  rh = row['REL_HUM_12_4']
  abs_hum = (6.112 * exp((17.67*t)/(t+243.5)) * rh * 2.1674)/(273.15+t)
  row['ABS_HUM_12_4'] = abs_hum
  return row

sample_df = sample_df.apply(lambda row: create_abs_humidity(row), axis=1)

g = sns.FacetGrid(sample_df, col='FIRE')
g.map(plt.hist, 'ABS_HUM_12_4')

"""### Optimizing features
Make bins for continous features:
1. Temperatures
2. Precipitation
3. Stats
"""

# Bin temperature
for temp_label in ['MEAN_TEMP', 'MAX_TEMP', 'MIN_TEMP', 'TEMP_12_4', 'DEW_POINT_TEMP_12_4']:
  sample_df['QUANTILE_'+temp_label] = pd.qcut(sample_df[temp_label], q=8, precision=0, duplicates='drop', labels=False)

# Bin precipitation, rain
for temp_label in ['TOTAL_RAIN', 'TOTAL_PRECIP']:
  sample_df['QUANTILE_'+temp_label] = pd.qcut(sample_df[temp_label], q=5, precision=0, duplicates='drop', labels=False)

# Bin relative humidity
sample_df['QUANTILE_REL_HUM_12_4'] = pd.qcut(sample_df['REL_HUM_12_4'], q=10, precision=0, duplicates='drop', labels=False)

# Bin absolute humidity
sample_df['QUANTILE_ABS_HUM_12_4'] = pd.qcut(sample_df['ABS_HUM_12_4'], q=5, precision=0, duplicates='drop', labels=False)

for stats_label in ['TOTAL_SIZE_HA_OLD', 'TOTAL_SIZE_HA_OLD', 'TOTAL_DURATION_OLD', 'AVERAGE_DURATION_OLD']:
  sample_df['QUANTILE_'+stats_label] = pd.qcut(sample_df[stats_label], q=5, precision=0, duplicates='drop', labels=False)

"""Create one hot encoding for eco zone, district, and region"""

eco_labels = ['ECOZONE', 'ECOREGION', 'ECODISTRICT']
for eco_label in eco_labels:
  one_hot = pd.get_dummies(sample_df[eco_label], drop_first=True).rename(columns=lambda label: f'{eco_label}_{label}')
  sample_df = sample_df.join(one_hot)

sample_df

sample_df.to_csv(root_path + f'Colab Data/{province}_processed_sample_dataset.csv.gz', compression='gzip', index=False)